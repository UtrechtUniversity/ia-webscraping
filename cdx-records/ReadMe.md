# Lambda: get CDX records

This project collects for a given set of inital urls CDX records from the Internet Archive.
The code in this project is run at AWS.
Terraform is used to deploy the following AWS resources:
- SQS queue 
- Lambda
- CloudWatch
- S3 bucket


## Getting started

  - [Prerequisites](#prerequisites)
  - [Copy the Project](#copy-the-project)
  - [Build Lambda function](#build-lambda-function)
  - [Update Scripts](#update-terraform-scripts)

### Prerequisites
To install and run this project you need to have the following prerequisites installed:
- (optional) install package manager. 
	- windows: [chocolatey](https://chocolatey.org/install), 
	- mac: [brew](https://brew.sh)
	- With a package manager it becomes easy to install/update the below prerequisites. 
    For example:  ```choco install awscli' ```
- [install aws cli](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html)
- [configure aws cli credentials](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html)
    create a profile and remember the name of this profile (if no name was specified, the name of the profile is 'default')
- install python3 
- install pip3
- install [terraform](https://www.terraform.io/downloads.html)
- create a personal S3 bucket in AWS (region: eu-central-1)

### Copy the Project

Create your own copy of the 'cdx-records' directory on your local client.

### Build lambda function

The 'build.sh' script will:
- install all requirements from the 'requirements.txt' file in the [lambda folder](/lambda-cdx-crunchbase-dev-mvos)
- create a zip file 
- calculate a hash of this zipfile and write this to 'example_lambda.zip.sha256'
- upload the zip file to the s3 bucket

#First update the build script: 
- line 16: provide your AWS bucket name (see [Prerequisites](#prerequisites))
- line 16: provide your AWS profile name (see [Prerequisites](#prerequisites)

#Then run the build script
```
$ ./build.sh 
```

### Update Terraform Scripts

In the [terraform folder](/terraform) create a file ```terraform.tfvars``` that lists terraform variables and the corresponding values:

```
bucket_name = [YOUR_BUCKET_NAME]

lambda_name = [YOUR_LAMBDA_NAME]

profile = [YOUR_AWS_PROFILE]
```
This file is automatically loaded by terraform and the values are assigned values to the variables in ```main.tf``` and ```provider.tf``` 

NB: The file ```backend.tf``` should be modified directly in the code :
	- line 5: provide your AWS bucket name (see [Prerequisites](#prerequisites))
	- line 7: provide your AWS profile name (see [Prerequisites](#prerequisites)
	- line 10: change the key with a key of your own, e.g. 'terraform/state/<your-lambda function>/terraform.tfstate' 


## Run
- [Deploy AWS resources](#deploy-aws-resources)
- [Fill SQS queue ](#fill-sqs-queue)
- [Test Function](#test-function)
- [Clean Up](#clean-up)


### Deploy AWS resources

#init
The terraform init command is used to initialize a working directory containing Terraform configuration files. This is the first command that should be run after writing a new Terraform configuration or cloning an existing one from version control. It is safe to run this command multiple times.
```
# Go to terraform folder
$ cd terraform

# Initialize terraform
$ terraform init
```

#plan
The terraform plan command is used to create an execution plan. Terraform performs a refresh, unless explicitly disabled, and then determines what actions are necessary to achieve the desired state specified in the configuration files. The optional -out argument can be used to save the generated plan to a file for later execution with terraform apply, which can be useful when running Terraform in automation.
```
$ terraform plan -out './plan'
```

#apply
The terraform apply command is used to apply the changes required to reach the desired state of the configuration, or the pre-determined set of actions generated by a terraform plan execution plan.
By using the “plan” command before “apply,” you’ll be aware of any unforeseen errors or unexpected resource creation/modification!
```
$ terraform apply "./plan"
```

### Fill SQS queue
The 'fill_sqs_queue.py' script creates a single SQS message in the SQS queue.

Before running the script, update the SQS queue that is hardcoded in the python code:
line 7: change the sqs ID in to the SQS ID that was created by 'terraform apply' command (check the terraform output)

set the following environment variable in your cmd prompt:
- 'AWS_PROFILE'=<'AWS profile'>

Execute the script:
```
# Go to cdx folder
$ cd ..

# Fill sqs queue
$ python fill_sqs_queue.py
```

### Test Function
Look up your newly create Lambda function in the AWS console (note, make sure that the console is set to the correct region 'eu-central-1').
Open the function and create a test event for your function. You can use the "hello world" event template.
The content of the test event is not used by the python code.
Run you're newly created test event and check the Lambda logs to see the result.

### Clean up
Run the following [command](https://www.terraform.io/docs/commands/destroy.html), to cleanup the AWS resources that were deployed by terraform:
```
# Go to terraform folder
$ cd terraform

# Clean up AWS resources
$ terraform destroy
```
